{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most accurate classifier for our data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import pandas as pd\n",
    "# Define timepoint of the trajectory\n",
    "time='1_20'\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features = pd.read_csv('../features/features_training1/features_{}.csv'.format(time))\n",
    "features.head(7)\n",
    "features_num=features.to_numpy()\n",
    "features[:] = np.nan_to_num(features_num)\n",
    "np.where(pd.isnull(features_num))\n",
    "RSEED=50\n",
    "features.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all ML classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cv\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Extract features and labels\n",
    "labels = features['quality']\n",
    "features = features.drop('quality', axis = 1)\n",
    "\n",
    "\n",
    "y = labels.map({'native':1,\"non-native\":0})\n",
    "x = features.values\n",
    "\n",
    "# Training/ Test Split\n",
    "x1,x2,y1,y2 =train_test_split(features, labels, random_state=0, test_size =0.25)\n",
    "\n",
    "\n",
    "# Initialize our classifiers\n",
    "gnb = GaussianNB()\n",
    "KNN = KNeighborsClassifier(n_neighbors=1)\n",
    "MNB = MultinomialNB()\n",
    "BNB = BernoulliNB()\n",
    "LR = LogisticRegression()\n",
    "SDG = SGDClassifier()\n",
    "SVC = SVC()\n",
    "LSVC = LinearSVC()\n",
    "NSVC = NuSVC()\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ML classifiers on trajectory stretch (K-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,  cross_val_predict , cross_validate\n",
    "\n",
    "# scikit-learn k-fold cross-validation\n",
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "# data sample\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "# prepare cross validation\n",
    "\n",
    "kf = RepeatedKFold(n_splits=10, n_repeats=10, random_state=2652124)\n",
    "# Training and Testing Sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, \n",
    "                                                                            test_size = 0.25, random_state = 42)\n",
    "\n",
    "rf_acc=[]\n",
    "gnb_acc=[]\n",
    "KNN_acc=[]\n",
    "BNB_acc=[]\n",
    "LR_acc=[]\n",
    "SVC_acc=[]\n",
    "SDG_acc=[]\n",
    "LSVC_acc=[]\n",
    "NSVC_acc=[]\n",
    "\n",
    "for train_index, test_index in kf.split(features, labels):\n",
    "    x1, x2, y1, y2 = x[train_index], x[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    # Train our classifier and test predict\n",
    "    RF.fit(x1, y1)\n",
    "    y2_RF_model = RF.predict(x2)\n",
    "    #print(\"Random Forest Accuracy :\", accuracy_score(y2, y2_RF_model))\n",
    "    #pprint(RF.get_params())\n",
    "    rf_acc.append(accuracy_score(y2, y2_RF_model))\n",
    "    \n",
    "    # Train our classifier and test predict\n",
    "    gnb.fit(x1, y1)\n",
    "    y2_GNB_model = gnb.predict(x2)\n",
    "    gnb_acc.append(accuracy_score(y2, y2_GNB_model))\n",
    "    #print(\"GaussianNB Accuracy :\", accuracy_score(y2, y2_GNB_model))\n",
    "    #pprint(gnb.get_params())\n",
    "\n",
    "    KNN.fit(x1,y1)\n",
    "    y2_KNN_model = KNN.predict(x2)\n",
    "    #print(\"KNN Accuracy :\", accuracy_score(y2, y2_KNN_model))\n",
    "    #pprint(KNN.get_params())\n",
    "    y2_GNB_model\n",
    "    KNN_acc.append(accuracy_score(y2, y2_KNN_model))\n",
    "    \n",
    "    #MNB.fit(x1,y1)\n",
    "    #y2_MNB_model = MNB.predict(x2)\n",
    "    #print(\"MNB Accuracy :\", accuracy_score(y2, y2_MNB_model))\n",
    "\n",
    "    BNB.fit(x1,y1)\n",
    "    y2_BNB_model = BNB.predict(x2)\n",
    "    #print(\"BNB Accuracy :\", accuracy_score(y2, y2_BNB_model))\n",
    "    #pprint(BNB.get_params())\n",
    "    BNB_acc.append(accuracy_score(y2, y2_BNB_model))\n",
    "\n",
    "    LR.fit(x1,y1)\n",
    "    y2_LR_model = LR.predict(x2)\n",
    "    #print(\"LR Accuracy :\", accuracy_score(y2, y2_LR_model))\n",
    "    #pprint(LR.get_params())\n",
    "    LR_acc.append(accuracy_score(y2, y2_LR_model))\n",
    "\n",
    "\n",
    "\n",
    "    SDG.fit(x1,y1)\n",
    "    y2_SDG_model = SDG.predict(x2)\n",
    "    #print(\"SDG Accuracy :\", accuracy_score(y2, y2_SDG_model))\n",
    "    #pprint(SDG.get_params())\n",
    "    SDG_acc.append(accuracy_score(y2, y2_SDG_model))\n",
    "\n",
    "\n",
    "    SVC.fit(x1,y1)\n",
    "    y2_SVC_model = SVC.predict(x2)\n",
    "    #print(\"SVC Accuracy :\", accuracy_score(y2, y2_SVC_model))\n",
    "    #pprint(SVC.get_params())\n",
    "    SVC_acc.append(accuracy_score(y2, y2_SVC_model))\n",
    "\n",
    "\n",
    "    LSVC.fit(x1,y1)\n",
    "    y2_LSVC_model = LSVC.predict(x2)\n",
    "    #print(\"LSVC Accuracy :\", accuracy_score(y2, y2_LSVC_model))\n",
    "    #pprint(LSVC.get_params())\n",
    "    LSVC_acc.append(accuracy_score(y2, y2_LSVC_model))\n",
    "\n",
    "\n",
    "    NSVC.fit(x1,y1)\n",
    "    y2_NSVC_model = NSVC.predict(x2)\n",
    "    #print(\"NSVC Accuracy :\", accuracy_score(y2, y2_NSVC_model))\n",
    "    NSVC_acc.append(accuracy_score(y2, y2_NSVC_model))\n",
    "    #pprint(NSVC.get_params())\n",
    "\n",
    "avg_RF_score = np.mean(rf_acc,axis=0)\n",
    "print(\"RF score :\", avg_RF_score)\n",
    "\n",
    "avg_gnb_score = np.mean(gnb_acc,axis=0)\n",
    "print(\"GNB score :\", avg_gnb_score)\n",
    "\n",
    "avg_KNN_score = np.mean(KNN_acc,axis=0)\n",
    "print(\"KNN score :\", avg_KNN_score)\n",
    "\n",
    "avg_BNB_score = np.mean(BNB_acc,axis=0)\n",
    "print(\"BNB score :\", avg_BNB_score)\n",
    "\n",
    "\n",
    "avg_LR_score = np.mean(LR_acc,axis=0)\n",
    "print(\"LR score :\", avg_LR_score)\n",
    "\n",
    "avg_SDG_score = np.mean(SDG_acc,axis=0)\n",
    "print(\"SDG score :\", avg_SDG_score)\n",
    "\n",
    "avg_SVC_score = np.mean(SVC_acc,axis=0)\n",
    "print(\"SVC score :\", avg_SVC_score)\n",
    "\n",
    "avg_LSVC_score = np.mean(LSVC_acc,axis=0)\n",
    "print(\"LSVC score :\", avg_LSVC_score)\n",
    "\n",
    "avg_NSVC_score = np.mean(NSVC_acc,axis=0)\n",
    "print(\"NSVC score :\", avg_NSVC_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
