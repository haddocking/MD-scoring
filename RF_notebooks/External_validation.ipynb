{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accompanied-decline",
   "metadata": {},
   "source": [
    "# Validate Random Forest classifier on external validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-madrid",
   "metadata": {},
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-focus",
   "metadata": {},
   "source": [
    "### Read the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time='80_100'\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features_train = pd.read_csv('../features/features_training2/features_{}.csv'.format(time))\n",
    "features_train.head(7)\n",
    "features_train_num=features_train.to_numpy()\n",
    "features_train[:] = np.nan_to_num(features_train_num)\n",
    "np.where(pd.isnull(features_train_num))\n",
    "RSEED=52\n",
    "features_train.fillna(features_train.mean())\n",
    "features_train.describe(include='all')\n",
    "labels_train = features_train['quality']\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features_train= features_train.drop('quality',axis = 1)\n",
    "y = labels_train.map({'native':1,\"non-native\":0})\n",
    "x = features_train.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-hundred",
   "metadata": {},
   "source": [
    "### Read the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in data as pandas dataframe and display first 5 rows\n",
    "features_test = pd.read_csv('../features/features_validation2/features_{}.csv'.format(time))\n",
    "features_test.head(7)\n",
    "features_test_num=features_test.to_numpy()\n",
    "features_test[:] = np.nan_to_num(features_test_num)\n",
    "np.where(pd.isnull(features_test_num))\n",
    "RSEED=50\n",
    "features_test.fillna(features_train.mean())\n",
    "features_test.describe(include='all')\n",
    "labels_test = features_test['quality']\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features_test= features_test.drop('quality',axis = 1)\n",
    "y1 = labels_test.map({'native':1,\"non-native\":0})\n",
    "x1 = features_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-parish",
   "metadata": {},
   "source": [
    "## Run the Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap= True, max_depth=50, max_features='auto', min_samples_leaf=1, min_samples_split=2, n_estimators = 1000,oob_score= True,\n",
    "                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score \n",
    "from sklearn.model_selection import cross_val_score,  cross_val_predict , cross_validate\n",
    "\n",
    "# Fit classifier on training set\n",
    "rf.fit(x,y)\n",
    "\n",
    "# Predict cross-validated (10x) score for training set\n",
    "scores = cross_val_score(rf, x, y, cv=10)\n",
    "print(\"Accuracy cv_score training set: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#Predict new data from validaiton set \n",
    "predicted = cross_val_predict(rf, x1, y1, cv=5)\n",
    "\n",
    "pred_labels=rf.predict(x1)\n",
    "\n",
    "# Calculate and print accuracy, f1-score, \n",
    "ex_accuracy=metrics.accuracy_score(y1, pred_labels)\n",
    "ex_f1=metrics.f1_score(y1, pred_labels)\n",
    "ex_precision=metrics.precision_score(y1, pred_labels)\n",
    "ex_recall=metrics.recall_score(y1, pred_labels)\n",
    "\n",
    "\n",
    "print('Accuracy for validation set: %0.2f ' % (ex_accuracy))\n",
    "print('f1-score  for validation set: %0.2f ' % (ex_f1))\n",
    "print('precision for validation set: %0.2f ' % (ex_precision))\n",
    "print('recall for validation set: %0.2f ' % (ex_recall))\n",
    "print('oob score:  %0.2f' %(rf.oob_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "sns.set(style=\"white\" )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Classification and ROC analysis\n",
    "\n",
    "# Run classifier with cross-validation and plot ROC curves\n",
    "cv = StratifiedKFold(n_splits=20,  random_state=2652124)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "\n",
    "probas_ = rf.fit(x, y).predict_proba(x1)\n",
    "    # Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y1, probas_[:, 1])\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.1,\n",
    "             )\n",
    "\n",
    "i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=1)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=1)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.1,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
